apiVersion: apps/v1
kind: 'Deployment'
metadata:
  name: 'prophet-redpanda-dev'
  namespace: 'default'
  labels:
    app: 'prophet-redpanda-dev'
spec:
  template:
    metadata:
        labels:
            app: 'prophet-redpanda-dev'
    spec:
      containers:
        - name: 'broker-0'
          image: 'docker.redpanda.com/redpandadata/redpanda:v24.1.9'
          args:
            - redpanda
            - start
            - --kafka-addr internal://0.0.0.0:9092,external://0.0.0.0:19092
            - --advertise-kafka-addr internal://broker-0:9092,external://localhost:19092
            - --pandaproxy-addr internal://0.0.0.0:8082,external://0.0.0.0:18082
            - --advertise-pandaproxy-addr internal://broker-0:8082,external://localhost:18082
            - --schema-registry-addr internal://0.0.0.0:8081,external://0.0.0.0:18081
            - --rpc-addr broker-0:33145
            - --advertise-rpc-addr broker-0:33145
            - --mode dev-container
            - --smp 1
            - --default-log-level=info
          ports:
            - containerPort: 18081
              hostPort: 18081
            - containerPort: 18082
            - containerPort: 19092
              hostPort: 19092
            - containerPort: 19644
        - name: 'console'
          image: 'docker.redpanda.com/redpandadata/console:v2.6.0'
          command:
            - /bin/sh
          args:
          - -c
          - 'echo "$$CONSOLE_CONFIG_FILE" > /tmp/config.yml; /app/console'
          env:
            - name: CONFIG_FILEPATH
              value: /tmp/config.yml
            - name: CONSOLE_CONFIG_FILE
              value: |
                kafka:
                  brokers: ["broker-0:9092"]
                  schemaRegistry:
                    enabled: true
                    urls: ["http://broker-0:8081"]
                redpanda:
                  adminApi:
                    enabled: true
                    urls: ["http://broker-0:9644"]
          ports:
            - containerPort: 8080
              hostPort: 8080
          volumeMounts:
            - mountPath: /var/lib/redpanda/data
              name: broker-volume
      volumes:
        - name: broker-volume
          persistentVolumeClaim:
            claimName: redpanda-dev


  selector:
    matchLabels:
      app: 'redpanda-dev'

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: "s-prophet-tracing"
data:
  uptrace.yml: |
    ##
    ## Uptrace configuration file.
    ## See https://uptrace.dev/get/config.html for details.
    ch:
      addr: localhost:9000
      user: default
      password:
      database: uptrace
      max_execution_time: 30s
    pg:
      addr: localhost:5432
      user: uptrace
      password: uptrace
      database: uptrace
    projects:
      # Conventionally, the first project is used to monitor Uptrace itself.
      - id: 1
        name: Uptrace
        # Token grants write access to the project. Keep a secret.
        token: project1_secret_token
        pinned_attrs:
          - service
          - host_name
          - deployment_environment
        # Group spans by deployment.environment attribute. 
        group_by_env: false
        # Group funcs spans by service.name attribute.
        group_funcs_by_service: false
        # Enable prom_compat if you want to use the project as a Prometheus datasource in Grafana.
        prom_compat: true

      # Other projects can be used to monitor your applications.
      # To monitor micro-services or multiple related services, use a single project.
      - id: 2
        name: "Materials Resources Development"
        token: materials_resources_secret_token
        pinned_attrs:
          - service
          - host_name
          - deployment_environment
        # Group spans by deployment.environment attribute.
        group_by_env: false
        # Group funcs spans by service.name attribute.
        group_funcs_by_service: false
        prom_compat: true
    
    auth:
      users:
        - name: Anonymous
          email: uptrace@localhost
          password: uptrace
          notify_by_email: true
      oidc:
    
    ch_schema:
      compression: ZSTD(3)
      replicated: false
      spans:
        ttl_delete: 7 DAY
        storage_policy: 'default'

      metrics:
        ttl_delete: 30 DAY
        storage_policy: 'default'

    listen:
      # OTLP/gRPC API.
      grpc:
        addr: ':14317'

      # OTLP/HTTP API and Uptrace API with UI.
      http:
        addr: ':14318'

    site:
    spans:
    metrics:
      # List of attributes to drop for being noisy.
      drop_attrs:
        - telemetry.sdk.language
        - telemetry.sdk.name
        - telemetry.sdk.version

      # The size of the Go chan used to buffer incoming measures.
      # If the buffer is full, Uptrace starts to drop measures.
      #buffer_size: 100000

      # The number of measures to insert in a single query.
      #batch_size: 10000

    ##
    ## uptrace-go client configuration.
    ## Uptrace sends internal telemetry here. Defaults to listen.grpc.addr.
    ##
    uptrace_go:
      # Enabled by default.
      disabled: true

    ##
    ## Logging configuration.
    ##
    logs:
      # Zap minimal logging level.
      # Valid values: DEBUG, INFO, WARN, ERROR, DPANIC, PANIC, FATAL.
      level: INFO

    # Secret key that is used to sign JWT tokens etc.
    secret_key: 102c1a557c314fc28198acd017960843

    # Enable to log HTTP requests and database queries.
    debug: false
  

  prometheus.yml: |
    global:
      scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
      evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.
      # scrape_timeout is set to the global default (10s).
    scrape_configs:
      - job_name: aggregated-trace-metrics
        static_configs:
          - targets: [ 'otel:8889' ]
  collector.yml: |
    extensions:
      health_check:
      pprof:
        endpoint: 0.0.0.0:1777
      zpages:
        endpoint: 0.0.0.0:55679
    
    receivers:
      otlp:
        protocols:
          grpc:
          http:
      hostmetrics:
        collection_interval: 10s
        scrapers:
          cpu:
          disk:
          load:
          filesystem:
          memory:
          network:
          paging:
      httpcheck:
        targets:
          - endpoint: 'http://localhost:13133/health/status'
            method: GET
          - endpoint: 'http://localhost:13134/health/status'
            method: GET
        collection_interval: 15s
      jaeger:
        protocols:
          grpc:
      postgresql:
        endpoint: postgres:5432
        transport: tcp
        username: uptrace
        password: uptrace
        databases:
          - uptrace
        tls:
          insecure: true
      prometheus/otelcol:
        config:
          scrape_configs:
            - job_name: 'otelcol'
              scrape_interval: 10s
              static_configs:
                - targets: ['0.0.0.0:8888']
    
    processors:
      resourcedetection:
        detectors: ['system']
      batch:
        send_batch_size: 10000
        timeout: 10s
    
    exporters:
      otlp/uptrace:
        endpoint: http://localhost:14317
        tls: { insecure: true }
        headers: { 'uptrace-dsn': 'http://materials_resources_secret_token@localhost:14318?grpc=14317' }
      prometheusremotewrite/uptrace:
        endpoint: 'http://localhost:14318/api/v1/prometheus/write'
        tls:
          insecure: true
        headers: { 'uptrace-dsn': 'http://materials_resources_secret_token@localhost:14318?grpc=14317' }
    
    service:
      telemetry:
        metrics:
          address: ':8888'
      #   logs:
      #     level: DEBUG
      pipelines:
        traces:
          receivers: [otlp, jaeger]
          processors: [batch]
          exporters: [otlp/uptrace]
        metrics:
          receivers: [otlp]
          processors: [batch]
          exporters: [otlp/uptrace]
        metrics/hostmetrics:
          receivers: [hostmetrics, postgresql, httpcheck]
          processors: [batch, resourcedetection]
          exporters: [otlp/uptrace]
        logs:
          receivers: [otlp]
          processors: [batch]
          exporters: [otlp/uptrace]
        metrics/prom:
          receivers: [prometheus/otelcol]
          processors: [batch]
          exporters: [prometheusremotewrite/uptrace]
      
      extensions: [health_check, pprof, zpages]
---
apiVersion: 'apps/v1'
kind: 'Deployment'
metadata:
  name: 's-prophet-tracing'
spec:
  selector:
    matchLabels:
      app: 's-prophet-tracing'
  template:
    spec:
      restartPolicy: 'Always'
      containers:
        - name: postgres
          image: postgres:15-alpine
          env:
            - name: PGDATA
              value: /var/lib/postgresql/data/pgdata
            - name: POSTGRES_USER
              value: uptrace
            - name: POSTGRES_PASSWORD
              value: uptrace
          ports:
            - containerPort: 5432
        - name: clickhouse
          image: clickhouse/clickhouse-server:23.7
          env:
            - name: CLICKHOUSE_DB
              value: uptrace
          volumeMounts:
            - mountPath: "/var/lib/clickhouse"
              name: "clichouse-data"
          ports:
            - containerPort: 8123
            - containerPort: 9000


        - name: collector
          image: ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib:0.94.0
          ports:
            - containerPort: 4317
              hostPort: 4317
            - containerPort: 4318
              hostPort: 4318
          args:
            - "--config"
            - "/etc/config/collector.yml"
          volumeMounts:
            - mountPath: "/etc/config/"
              name: config
        - name: uptrace
          image: uptrace/uptrace:1.7.2
          restartPolicy: on-failure
          ports:
            - containerPort: 14317
              hostPort: 14317
            - containerPort: 14318
              hostPort: 14318
          volumeMounts:
            - mountPath: "/etc/uptrace/"
              name: "config"
        - name: prometheus
          image: quay.io/prometheus/prometheus:v2.51.2
          args:
            - "--config.file=/etc/config/prometheus.yml"
          ports:
            - containerPort: 9090
              hostPort: 9090
          volumeMounts:
            - mountPath: "/etc/config/"
              name: config
      volumes:
        - name: "clichouse-data"
          persistentVolumeClaim:
            claimName: "clickhouse-data"
        - name: "config"
          configMap:
            name: "s-prophet-tracing"


